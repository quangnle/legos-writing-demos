let lander;
let gravity = 0.05;
let wind = 0;
let groundY;
let landed = false;
let crashed = false;
let landingZone;
let qTable = {};
let actions = ["NONE", "UP", "LEFT", "RIGHT"];
let epsilon = 0.1;
let alpha = 0.2; // T·ªëc ƒë·ªô h·ªçc, alpha c√†ng l·ªõn th√¨ t·ªëc ƒë·ªô h·ªçc c√†ng nhanh nh∆∞ng d·ªÖ b·ªã overfitting
let gamma = 0.95; // H·ªá s·ªë gi·∫£m gi√°, gamma c√†ng l·ªõn th√¨ c√†ng ch√∫ tr·ªçng ƒë·∫øn ph·∫ßn th∆∞·ªüng trong t∆∞∆°ng lai
let state; // Tr·∫°ng th√°i hi·ªán t·∫°i c·ªßa t√†u v≈© tr·ª•
let previousState; // Tr·∫°ng th√°i tr∆∞·ªõc ƒë√≥ c·ªßa t√†u v≈© tr·ª•
let previousAction; // H√†nh ƒë·ªông tr∆∞·ªõc ƒë√≥ c·ªßa t√†u v≈© tr·ª•
let frameCounter = 0;
let episodeReward = 0; // Ph·∫ßn th∆∞·ªüng cho m·ªôt l·∫ßn t·∫≠p ƒë√°p
let rewardHistory = [];
let maxHistory = 150; // S·ªë l∆∞·ª£ng ph·∫ßn th∆∞·ªüng t·ªëi ƒëa ƒë∆∞·ª£c l∆∞u tr·ªØ trong l·ªãch s·ª≠
let counter = 0;
let successCounter = 0;
let failCounter = 0;
let safeVy = 3.8; // T·ªëc ƒë·ªô r∆°i t·ªëi ƒëa cho ph√©p khi h·∫° c√°nh
let safeVx = 2.2; // T·ªëc ƒë·ªô d·ªãch tr√°i ph·∫£i t·ªëi ƒëa cho ph√©p khi h·∫° c√°nh
let maxWindVariation = 0.0003; // Bi·∫øn thi√™n gi√≥ t·ªëi ƒëa
let timer = 0; // Th·ªùi gian bay t√≠nh b·∫±ng gi√¢y

function setup() {
    createCanvas(600, 400);
    groundY = height - 40;
    resetEpisode();
    landingZone = {x: width / 2 - 40, w: 80};
}

function resetEpisode() {

    // L∆∞u tr·ªØ k·∫øt qu·∫£ c·ªßa l·∫ßn tr∆∞·ªõc
    if (rewardHistory.length > maxHistory) rewardHistory.shift();
    rewardHistory.push(successCounter / (failCounter + epsilon)); // T√≠nh t·ª∑ l·ªá th√†nh c√¥ng

    console.log(`Episode reward: ${episodeReward}`);

    // Kh·ªüi t·∫°o l·∫°i c√°c bi·∫øn cho m·ªôt l·∫ßn t·∫≠p m·ªõi
    lander = new Lander();
    landed = false;
    crashed = false;
    frameCounter = 0;
    previousState = null;
    previousAction = null;    
    episodeReward = 0;
    counter++;
    timer = 0;
}

function draw() {
    background(30);
    strokeWeight(0.5);
    drawGround();
    drawLandingZone();
    drawRewardGraph();

    // T·∫°o gi√≥ ng·∫´u nhi√™n
    let windVariation = random(-maxWindVariation, maxWindVariation);
    wind += windVariation;
    wind = constrain(wind, -0.1, 0.1);

    if (!landed && !crashed) {
        state = getState();
        let action = chooseAction(state);
        applyAction(action);

        lander.applyGravity(); // √°p d·ª•ng tr·ªçng l·ª±c
        lander.applyWind(wind); // √°p d·ª•ng gi√≥
        lander.update(); // c·∫≠p nh·∫≠t v·ªã tr√≠
        lander.checkCollision(); // ki·ªÉm tra va ch·∫°m
        lander.checkBounds(); // ki·ªÉm tra ra ngo√†i bi√™n

        let reward = getReward(timer); // t√≠nh ph·∫ßn th∆∞·ªüng
        episodeReward += reward; // c·∫≠p nh·∫≠t ph·∫ßn th∆∞·ªüng cho l·∫ßn t·∫≠p ƒë√°p n√†y
        updateQTable(previousState, previousAction, reward, state); // c·∫≠p nh·∫≠t Q table

        previousState = state;
        previousAction = action;
    } else {
        if (frameCounter > 180) resetEpisode(); // kh·ªüi ƒë·ªông l·∫°i sau 3 gi√¢y n·∫øu h·∫° c√°nh th√†nh c√¥ng ho·∫∑c va ch·∫°m
        if (landed) {
            lander.vy = 0; // d·ª´ng t√†u l·∫°i khi h·∫° c√°nh th√†nh c√¥ng
            lander.vx = 0;
        }
        if (crashed) {
            lander.vy = 0; // d·ª´ng t√†u l·∫°i khi va ch·∫°m
            lander.vx = 0;
            // v·∫Ω k√Ω hi·ªáu n·ªï khi va ch·∫°m
            fill(255, 0, 0);
            textSize(25);
            text("üí•", lander.x - 20, lander.y - 10);
        }
    }

    frameCounter++;
    timer ++; // th·ªùi gian t√≠nh b·∫±ng gi√¢y
    if (!crashed) {
        lander.draw(); // v·∫Ω t√†u v≈© tr·ª•
    }
    displayStatus(); // hi·ªÉn th·ªã tr·∫°ng th√°i
}

function drawGround() {
    fill(80, 200, 100);
    rect(0, groundY, width, height - groundY);
}

function drawLandingZone() {
    fill(100, 255, 255);
    rect(landingZone.x, groundY, landingZone.w, 10);
}

function drawRewardGraph() {
    let graphX = 10,
        graphY = 80,
        graphW = maxHistory,
        graphH = 50;

    fill(0);
    stroke(255);
    rect(graphX, graphY, graphW, graphH);
    noFill();
    beginShape();
    stroke(100, 255, 100);
    for (let i = 0; i < rewardHistory.length; i++) {
        let x = map(i, 0, maxHistory, graphX, graphX + graphW);
        let y = map(rewardHistory[i], -0.1, 1.1, graphY + graphH, graphY);
        vertex(x, y);
    }
    endShape();
    fill(255);
    textSize(9);
    text(`Reward over time (# trials = ${counter}, rate: ${successCounter} / ${failCounter})`, graphX, graphY - 5);
}

function displayStatus() {
    fill(255);
    textSize(9);
    if (landed) {
        text("‚úÖ Landed Successfully in Zone!", 10, 20);    
        
    } else if (crashed) {
        text("üí• Crashed!", 10, 20);
    } else {
        text("Q-learning pilot active...", 10, 20);
    }

    text(`Velocity: vy=${lander.vy.toFixed(2)}, vx=${lander.vx.toFixed(2)}`, 10, 40);
    text(`Wind: ${wind.toFixed(3)}`, 10, 60);
}

function getState() {
    let x = floor(lander.x / 40);
    let y = floor(lander.y / 40);
    let vx = floor(lander.vx * 10);
    let vy = floor(lander.vy * 10);
    return `${x},${y},${vx},${vy}`;
}

function chooseAction(state) {
    if (!qTable[state]) qTable[state] = Array(actions.length).fill(0);
    if (random() < epsilon) {
        return floor(random(actions.length));
    } else {
        return qTable[state].indexOf(Math.max(...qTable[state]));
    }
}

function applyAction(action) {
    switch (actions[action]) {
        case "UP":
            lander.thrustUp();
            break;
        case "LEFT":
            lander.thrustLeft();
            break;
        case "RIGHT":
            lander.thrustRight();
            break;
    }
}

function getReward(t = 0) {
    const maxDistance = width / 2; // Kho·∫£ng c√°ch t·ªëi ƒëa t·ª´ t√¢m ƒë·∫øn bi√™n
    const epsilon = 0.1; // H·∫±ng s·ªë nh·ªè tr√°nh chia cho 0

    // Ki·ªÉm tra tr·∫°ng th√°i khi ch·∫°m ƒë·∫•t
    if (lander.y <= groundY) {
        const inLandingZone = lander.x >= (landingZone.x - landingZone.w / 2) && 
                              lander.x <= (landingZone.x + landingZone.w / 2);
        const safeVelocity = Math.abs(lander.vx) < 0.5 && Math.abs(lander.vy) < 1.0;
        
        if (inLandingZone && safeVelocity) {
            return 10000; // H·∫° c√°nh th√†nh c√¥ng
        } else {
            return -10000; // Va ch·∫°m ho·∫∑c h·∫° c√°nh th·∫•t b·∫°i
        }
    }

    // Khi ƒëang bay
    let reward = 0;

    // Kho·∫£ng c√°ch ƒë·∫øn trung t√¢m v√πng h·∫° c√°nh
    let distanceToLandingZone = Math.abs(lander.x - (landingZone.x + landingZone.w / 2));
    reward += -distanceToLandingZone / maxDistance; // Chu·∫©n h√≥a kho·∫£ng c√°ch

    // Ph·∫°t v·∫≠n t·ªëc, tƒÉng m·∫°nh khi g·∫ßn m·∫∑t ƒë·∫•t
    let distanceToGround = Math.abs(lander.y - groundY);
    let totalVelocity = Math.abs(lander.vx) + Math.abs(lander.vy);
    reward += -totalVelocity / (Math.sqrt(distanceToGround) + epsilon);

    // Ph·∫°t th·ªùi gian
    reward += -t / 10; // TƒÉng h√¨nh ph·∫°t th·ªùi gian

    return reward;
}

function updateQTable(prevState, action, reward, newState) {
    if (!prevState || action === null) return; // kh√¥ng c·∫≠p nh·∫≠t n·∫øu kh√¥ng c√≥ tr·∫°ng th√°i tr∆∞·ªõc ho·∫∑c h√†nh ƒë·ªông
    // kh·ªüi t·∫°o Q-table n·∫øu ch∆∞a c√≥
    if (!qTable[prevState]) qTable[prevState] = Array(actions.length).fill(0); 
    if (!qTable[newState]) qTable[newState] = Array(actions.length).fill(0); 

    // c·∫≠p nh·∫≠t Q-table theo c√¥ng th·ª©c Q-learning
    let oldValue = qTable[prevState][action]; // gi√° tr·ªã Q c≈©
    let futureValue = Math.max(...qTable[newState]); // gi√° tr·ªã Q t·ªëi ƒëa c·ªßa tr·∫°ng th√°i m·ªõi
    // c·∫≠p nh·∫≠t gi√° tr·ªã Q theo c√¥ng th·ª©c Q-learning
    // v·ªõi c√¥ng th·ª©c l√† Q(s, a) = Q(s, a) + Œ± * (r + Œ≥ * max(Q(s', a')) - Q(s, a))
    // trong ƒë√≥:
    // - Q(s, a): gi√° tr·ªã Q c·ªßa tr·∫°ng th√°i s v√† h√†nh ƒë·ªông a
    // - r: ph·∫ßn th∆∞·ªüng nh·∫≠n ƒë∆∞·ª£c sau khi th·ª±c hi·ªán h√†nh ƒë·ªông a
    // - Œ≥: h·ªá s·ªë gi·∫£m gi√° (discount factor)
    // - max(Q(s', a')): gi√° tr·ªã Q t·ªëi ƒëa c·ªßa tr·∫°ng th√°i m·ªõi s'
    // - Œ±: h·ªá s·ªë h·ªçc (learning rate)    
    qTable[prevState][action] =
        oldValue + alpha * (reward + gamma * futureValue - oldValue);
}
